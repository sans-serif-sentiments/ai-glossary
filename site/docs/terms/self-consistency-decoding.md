<!--
  This file is auto-generated by scripts/render_docs.py. Do not edit manually.
-->

# self-consistency decoding

**Aliases:** self-consistency, majority-vote reasoning
**Categories:** LLM Core
**Roles:** Engineering & Platform, Data Science & Research
**Part of speech:** `process`
**Status:** <span class="status-chip status-approved">Approved</span> (Last reviewed: 2025-10-10)

## Role takeaways
- **Engineering & Platform:** Document implementation requirements and operational caveats.
- **Data Science & Research:** Incorporate the metric or method into evaluation pipelines.

## Practice & apply
- Prototype behaviour changes in a sandbox notebook and capture prompt or decoding settings for others.
- Share findings with enablement so downstream teams understand model implications.
- Share takeaways with the accountable roles listed above so actions land with the right owners.

## Short definition
Decoding strategy that samples multiple reasoning paths and aggregates the most consistent answer.

## Long definition
Self-consistency decoding runs a model several times with chain-of-thought prompts, then selects the answer that appears most frequently across the sampled reasoning paths. The approach boosts accuracy on reasoning tasks by reducing the impact of any single hallucinated chain. Engineers trade off latency and cost for higher reliability, while data scientists evaluate how many samples are needed to meaningfully improve accuracy. The technique pairs well with automated checkers that verify the final answer. Without careful tuning, self-consistency can reinforce common but incorrect answers or leak sensitive reasoning traces.

## Audience perspectives
- **Exec:** Use self-consistency when critical decisions require higher reasoning confidence.
- **Engineer:** Balance sampling counts with latency budgets and audit reasoning traces for policy compliance.

## Examples
**Do**
- Combine self-consistency with validators that check math or policy compliance.
- Log sampled chains for debugging and evaluation.

**Don't**
- Assume majority vote guarantees correctness without external checks.
- Leak sensitive instruction text in stored reasoning chains.

## Governance
- **NIST RMF tags:** monitoring, risk_management
- **Risk notes:** Sampling multiple chains increases cost and potential exposure of sensitive intermediate reasoning.

## Relationships
- **Broader:** decoding
- **Related:** chain-of-thought prompting, robust prompting, evaluation harness

!!! info "Something missing?"
    Suggest examples or clarifications via the [term request intake](../term-request.md) and mention 'self-consistency decoding'.

## Citations
- [Google – Self-Consistency Improves Chain of Thought](https://arxiv.org/abs/2203.11171)
- [OpenAI – Better Language Models and Their Implications](https://arxiv.org/abs/2005.14165)

_License: CC BY-SA 4.0_

_Source file: `data/terms/self-consistency-decoding.yml`_
