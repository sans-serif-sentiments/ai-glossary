<!--
  This file is auto-generated by scripts/render_docs.py. Do not edit manually.
-->

# fine-tuning

**Aliases:** model adaptation, supervised fine-tuning
**Categories:** Optimization & Efficiency
**Roles:** Data Science & Research, Engineering & Platform
**Part of speech:** `process`
**Status:** <span class="status-chip status-approved">Approved</span> (Last reviewed: 2025-10-10)

## Role takeaways
- **Data Science & Research:** Incorporate the metric or method into evaluation pipelines.
- **Engineering & Platform:** Document implementation requirements and operational caveats.

## Practice & apply
- Record before-and-after performance metrics when applying this optimisation technique.
- Document trade-offs for product and policy partners using the glossary's language.
- Share takeaways with the accountable roles listed above so actions land with the right owners.

## Short definition
Additional training that adapts a pretrained model to a specific task or domain.

## Long definition
Fine-tuning continues training from a pretrained checkpoint using a curated dataset that reflects the target task, tone, or policy. By adjusting weights on top of broad foundation knowledge, teams achieve better accuracy and alignment than prompt engineering alone. Approaches include supervised fine-tuning, reinforcement learning from human feedback, parameter-efficient methods like LoRA, and combinations with synthetic data generation. Product leaders plan fine-tuning roadmaps to differentiate experiences or enforce brand voice, while engineers manage hyperparameters, data balancing, and evaluation suites to prevent catastrophic forgetting. Governance stakeholders scrutinize fine-tuning inputs for licensing, privacy, and bias risks, requiring documentation of provenance and review sign-offs. Because fine-tuned models can drift from base guarantees, organizations version checkpoints, run regression tests, and maintain rollback plans to satisfy compliance obligations and operational reliability.

## Audience perspectives
- **Exec:** Fine-tuning teaches a general model to speak in the organizationâ€™s voice and handle domain-specific tasks.
- **Engineer:** Continue training a pretrained model on labeled or preference data, tracking hyperparameters, evals, and release packaging.

## Examples
**Do**
- Store data lineage and evaluation results for every fine-tuned checkpoint before deployment.

**Don't**
- Blend proprietary and open datasets without clarifying licenses and usage rights.

## Governance
- **NIST RMF tags:** accountability, validity
- **Risk notes:** Uncontrolled fine-tuning can override safety mitigations or introduce licensed data without traceability.

## Relationships
- **Broader:** model training
- **Narrower:** low-rank adaptation, reinforcement learning from human feedback
- **Related:** knowledge distillation, evaluation, alignment

!!! info "Something missing?"
    Suggest examples or clarifications via the [term request intake](../term-request.md) and mention 'fine-tuning'.

## Citations
- [Google ML Glossary](https://developers.google.com/machine-learning/glossary)
- [Hugging Face Glossary](https://huggingface.co/docs/transformers/en/glossary)
- [NIST AI RMF Glossary](https://www.nist.gov/itl/ai-risk-management-framework)

_License: CC BY-SA 4.0_

_Source file: `data/terms/fine-tuning.yml`_
