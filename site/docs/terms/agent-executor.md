<!--
  This file is auto-generated by scripts/render_docs.py. Do not edit manually.
-->

# agent executor

**Aliases:** agent run loop, agent controller
**Categories:** Agents & Tooling
**Roles:** Engineering & Platform, Product & Program Managers
**Part of speech:** `concept`
**Status:** <span class="status-chip status-approved">Approved</span> (Last reviewed: 2025-10-10)

## Role takeaways
- **Engineering & Platform:** Document implementation requirements and operational caveats.
- **Product & Program Managers:** Translate this concept into user impact and rollout plans.

## Practice & apply
- Audit exposed tools against the safeguards described and document approval paths.
- Test hand-offs with human reviewers to confirm the safety expectations captured here are met.
- Share takeaways with the accountable roles listed above so actions land with the right owners.

## Short definition
Controller layer that schedules planning, tool calls, and stop conditions so an AI agent completes tasks safely.

## Long definition
An agent executor is the control loop that wraps a language model with planning, tool routing, memory updates, and termination rules. It interprets the model's action plans, selects the right tool or retriever, enforces guardrails, and decides when the task is complete or needs human escalation. Mature executors persist interim state, log each decision for observability, and cap iteration budgets to avoid runaway loops. Product teams set policies for the executor about tool eligibility or human approval, while engineers own the orchestration logic that keeps the agent explainable and reversible. Without a disciplined executor, agent architectures tend to overrun budgets, trigger risky actions, or hide provenance needed for governance reviews.

## Audience perspectives
- **Exec:** Clarify what control layer governs autonomous workflows so you can scope approvals and accountability.
- **Engineer:** Treat the executor as orchestrator code: build deterministic plans, enforce stop criteria, and log every action.

## Examples
**Do**
- Cap the number of tool invocations per task and emit structured traces for monitoring.
- Define escalation triggers that halt the loop when confidence drops or policies flag sensitive data.

**Don't**
- Let the agent call privileged tools without a permissions check in the executor.
- Ship an executor without human-readable logs or telemetry for audit reviews.

## Governance
- **NIST RMF tags:** governance, risk_management, transparency
- **Risk notes:** Unbounded loops or opaque routing decisions can create safety, compliance, and cost exposures.

## Relationships
- **Broader:** agentic ai, tool use
- **Related:** guardrails, retrieval-augmented generation, ml ops

!!! info "Something missing?"
    Suggest examples or clarifications via the [term request intake](../term-request.md) and mention 'agent executor'.

## Citations
- [LangChain Documentation – Agent Executors](https://api.python.langchain.com/en/latest/langchain/agents.html)
- [Anthropic Docs – Building Agentic Workflows](https://docs.anthropic.com/claude/docs/agentic-workflows)

_License: CC BY-SA 4.0_

_Source file: `data/terms/agent-executor.yml`_
