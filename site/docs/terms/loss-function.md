<!--
  This file is auto-generated by scripts/render_docs.py. Do not edit manually.
-->

# loss function

**Aliases:** cost function, objective function
**Categories:** Foundations
**Roles:** Data Science & Research, Engineering & Platform, Product & Program Managers, Policy & Risk
**Part of speech:** `noun`
**Status:** <span class="status-chip status-approved">Approved</span> (Last reviewed: 2025-09-29)

## Role takeaways
- **Data Science & Research:** Incorporate the metric or method into evaluation pipelines.
- **Engineering & Platform:** Document implementation requirements and operational caveats.
- **Product & Program Managers:** Translate this concept into user impact and rollout plans.
- **Policy & Risk:** Map the definition to governance controls and review checklists.

## Practice & apply
- Add this concept to onboarding materials so teammates share a common baseline.
- Link supporting research or documentation in your internal wiki for deeper study.
- Share takeaways with the accountable roles listed above so actions land with the right owners.

## Short definition
Mathematical rule that scores how far model predictions deviate from desired targets.

## Long definition
A loss function translates model performance into a single scalar so optimisation algorithms know which direction to move. Classification systems rely on cross-entropy or focal loss to punish incorrect labels, while regression models often use mean squared error or Huber loss to balance sensitivity to outliers. Product and policy partners read loss definitions to understand which business or compliance outcomes the model optimises, and engineers adjust them when priorities shift from accuracy to calibration, fairness, or cost. Clear documentation of the loss function protects teams from accidental regressions, especially when a model serves multiple stakeholders who care about different metrics.

## Audience perspectives
- **Exec:** The loss function is the scorecard that tells the training loop if changes made the model better or worse.
- **Engineer:** Define differentiable losses aligned with business metrics; monitor surrogate vs. offline KPI gaps and adjust weighting as needed.

## Examples
**Do**
- Document the exact loss, weighting, and class balancing strategy in model cards and runbooks.
- Evaluate fairness metrics alongside the chosen loss before updating production thresholds.

**Don't**
- Swap in a new loss function without revalidating calibration and downstream KPIs.
- Optimise purely for training loss when evaluation or business metrics tell a different story.

## Governance
- **NIST RMF tags:** validity, transparency
- **Risk notes:** Misaligned losses can optimise for the wrong behaviour, creating governance or compliance gaps if not reviewed.

## Relationships
- **Broader:** evaluation
- **Related:** gradient descent, regularization, bias-variance tradeoff

!!! info "Something missing?"
    Suggest examples or clarifications via the [term request intake](../term-request.md) and mention 'loss function'.

## Citations
- [Google ML Crash Course](https://developers.google.com/machine-learning/crash-course/glossary#loss)
- [Wikipedia â€“ Loss Function](https://en.wikipedia.org/wiki/Loss_function)
- [Machine Learning Mastery](https://machinelearningmastery.com/loss-and-loss-functions/)

_License: CC BY-SA 4.0_

_Source file: `data/terms/loss-function.yml`_
