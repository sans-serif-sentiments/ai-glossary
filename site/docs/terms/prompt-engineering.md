<!--
  This file is auto-generated by scripts/render_docs.py. Do not edit manually.
-->

# prompt engineering

**Aliases:** prompt design, prompt scripting
**Categories:** LLM Core
**Roles:** Data Science & Research, Engineering & Platform, Product & Program Managers
**Part of speech:** `process`
**Status:** <span class="status-chip status-approved">Approved</span> (Last reviewed: 2025-10-10)

!!! tip "Put it into practice"
    Dive into the [Prompt Engineering Playbook](../prompting.md) for workflows and checklists.

## Role takeaways
- **Data Science & Research:** Incorporate the metric or method into evaluation pipelines.
- **Engineering & Platform:** Document implementation requirements and operational caveats.
- **Product & Program Managers:** Translate this concept into user impact and rollout plans.

## Practice & apply
- Prototype behaviour changes in a sandbox notebook and capture prompt or decoding settings for others.
- Share findings with enablement so downstream teams understand model implications.
- Share takeaways with the accountable roles listed above so actions land with the right owners.

## Short definition
Crafting and testing prompts to steer model behavior toward desired outcomes.

## Long definition
Prompt engineering involves designing the instructions, examples, and context provided to a language model so it produces reliable, policy-compliant responses. Practitioners experiment with phrasing, ordering, few-shot examples, and formatting cues to influence reasoning steps or output structure. The discipline has evolved from ad-hoc experimentation to a structured workflow that includes prompt libraries, evaluation harnesses, and version control. Prompt engineers collaborate with product, legal, and safety teams to encode business rules, tone, and disallowed behaviors, often in tandem with system prompts and guardrails. They also balance token budgets against performance, ensuring prompts fit within context windows while still providing the necessary guidance. Governance functions expect prompt changes to pass through review queues, since a seemingly small tweak can alter safety posture or introduce bias.

## Audience perspectives
- **Exec:** Prompt engineering is how we teach the model to act like our product or policy experts.
- **Engineer:** Systematic design of prompt structure, exemplars, and metadata; evaluated via regression suites to manage behavior drift.

## Examples
**Do**
- Version prompts and run automated evals before rolling them out to production flows.

**Don't**
- Copy prompts between domains without revisiting legal and safety requirements.

## Governance
- **NIST RMF tags:** accountability, transparency
- **Risk notes:** Unreviewed prompt changes can bypass controls and result in unsafe or misleading outputs.

## Relationships
- **Broader:** human-in-the-loop
- **Narrower:** few-shot prompting, chain-of-thought prompting
- **Related:** system prompt, guardrails, evaluation

!!! info "Something missing?"
    Suggest examples or clarifications via the [term request intake](../term-request.md) and mention 'prompt engineering'.

## Citations
- [Hugging Face Glossary](https://huggingface.co/docs/transformers/en/glossary)
- [Learn Prompting â€“ Introduction](https://www.promptingguide.ai/introduction)
- [Wikipedia AI Glossary](https://en.wikipedia.org/wiki/Glossary_of_artificial_intelligence)

_License: CC BY-SA 4.0_

_Source file: `data/terms/prompt-engineering.yml`_
