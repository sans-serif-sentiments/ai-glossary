<!--
  This file is auto-generated by scripts/render_docs.py. Do not edit manually.
-->

# feature engineering

**Aliases:** feature design, feature extraction
**Categories:** Foundations
**Roles:** Data Science & Research, Engineering & Platform, Product & Program Managers
**Part of speech:** `process`
**Status:** <span class="status-chip status-approved">Approved</span> (Last reviewed: 2025-10-10)

## Role takeaways
- **Data Science & Research:** Incorporate the metric or method into evaluation pipelines.
- **Engineering & Platform:** Document implementation requirements and operational caveats.
- **Product & Program Managers:** Translate this concept into user impact and rollout plans.

## Practice & apply
- Add this concept to onboarding materials so teammates share a common baseline.
- Link supporting research or documentation in your internal wiki for deeper study.
- Share takeaways with the accountable roles listed above so actions land with the right owners.

## Short definition
Transforming raw data into model-ready features that improve signal, fairness, and maintainability.

## Long definition
Feature engineering covers the techniques used to convert raw logs, text, images, or structured records into inputs a model can learn from. It spans cleaning, normalization, aggregation, embedding, and generation of domain-specific indicators. Thoughtful feature engineering improves generalization, reduces noise, and encodes policy guardrails early in the pipeline. Data scientists prototype feature pipelines, engineers productionize them with monitoring and lineage, and product teams align feature choices with user journeys and governance constraints. Documented feature logic also accelerates audits and root cause analysis when behaviour shifts in production.

## Audience perspectives
- **Exec:** Feature engineering is how we turn messy data into reliable signals the model can use.
- **Engineer:** Version feature code, validate statistical drift, and partner with governance to review sensitive attributes.

## Examples
**Do**
- Log transformations and scaling choices alongside the model so they stay in sync across environments.
- Run fairness and privacy checks when introducing features derived from sensitive sources.

**Don't**
- Ship handcrafted features without automated tests or lineage traces.
- Overfit by generating thousands of highly specific features with no regularization plan.

## Governance
- **NIST RMF tags:** data_quality, privacy
- **Risk notes:** Opaque feature pipelines hide bias, privacy violations, and drift triggers, making incidents harder to manage.

## Relationships
- **Related:** training data, regularization, bias-variance tradeoff, ml ops

!!! info "Something missing?"
    Suggest examples or clarifications via the [term request intake](../term-request.md) and mention 'feature engineering'.

## Citations
- [Google ML Glossary](https://developers.google.com/machine-learning/glossary#feature-engineering)
- [NIST AI Risk Management Framework](https://nvlpubs.nist.gov/nistpubs/ai/NIST.AI.100-1.pdf)
- [Microsoft Responsible AI Standard](https://learn.microsoft.com/en-us/azure/architecture/guide/responsible-innovation/)

_License: CC BY-SA 4.0_

_Source file: `data/terms/feature-engineering.yml`_
