<!--
  This file is auto-generated by scripts/render_docs.py. Do not edit manually.
-->

# escalation policy

**Aliases:** human escalation policy, handoff policy
**Categories:** Governance & Risk
**Roles:** Product & Program Managers, Policy & Risk, Security & Trust, Engineering & Platform
**Part of speech:** `noun_phrase`
**Status:** <span class="status-chip status-approved">Approved</span> (Last reviewed: 2025-10-09)

## Role takeaways
- **Product & Program Managers:** Translate this concept into user impact and rollout plans.
- **Policy & Risk:** Map the definition to governance controls and review checklists.
- **Security & Trust:** Plan monitoring and abuse prevention scenarios influenced by this term.
- **Engineering & Platform:** Document implementation requirements and operational caveats.

## Practice & apply
- Map this term to the governance dashboard and record accountable owners in the backlog.
- Review current regulatory guidance or internal policy notes linked from the resources page before sign-off.
- Share takeaways with the accountable roles listed above so actions land with the right owners.

## Short definition
Playbook that defines when and how AI systems route control to human reviewers.

## Long definition
An escalation policy documents the conditions that trigger human intervention during automated workflows. For AI systems, it specifies risk thresholds, user signals, compliance events, and operational failures that require a person to review or take over. The policy names accountable roles, time-to-response expectations, and communication paths so incidents resolve quickly. Product teams embed escalation hooks in UX flows, engineering implements the routing logic, and security or policy leaders ensure the policy covers legal and ethical obligations. Without a maintained policy, escalations become ad hoc, increasing the chance that sensitive actions remain unreviewed or stuck in queues.

## Audience perspectives
- **Exec:** Use escalation policies to prove that sensitive AI decisions receive timely human scrutiny.
- **Engineer:** Wire instrumentation that triggers the policy reliably and logs every escalation for auditing.

## Examples
**Do**
- Define severity tiers with maximum response windows for each reviewer group.
- Test escalation paths during chaos exercises to confirm alerts reach on-call owners.

**Don't**
- Rely on verbal agreements about who will intervene when policies fire.
- Allow blocked escalations to sit without rerouting or notifying backups.

## Governance
- **NIST RMF tags:** governance, monitoring, risk_management
- **Risk notes:** Undefined escalation paths leave high-impact failures unreviewed and erode regulatory trust.

## Relationships
- **Broader:** ai incident response, guardrail policy
- **Related:** human handoff, risk register, safety spec

!!! info "Something missing?"
    Suggest examples or clarifications via the [term request intake](../term-request.md) and mention 'escalation policy'.

## Citations
- [Microsoft – AI Safety Guidance](https://learn.microsoft.com/en-us/azure/ai-foundry/responsible-ai/openai/overview)
- [Partnership on AI – Responsible AI for Customer Service](https://learn.microsoft.com/en-us/azure/ai-foundry/openai/concepts/prompt-engineering)

_License: CC BY-SA 4.0_

_Source file: `data/terms/escalation-policy.yml`_
