<!--
  This file is auto-generated by scripts/render_docs.py. Do not edit manually.
-->

# diffusion model

**Aliases:** denoising diffusion model, score-based model
**Categories:** Foundations, LLM Core
**Roles:** Engineering & Platform, Data Science & Research, Product & Program Managers, Communications & Enablement
**Part of speech:** `noun`
**Status:** <span class="status-chip status-approved">Approved</span> (Last reviewed: 2025-10-10)

## Role takeaways
- **Engineering & Platform:** Document implementation requirements and operational caveats.
- **Data Science & Research:** Incorporate the metric or method into evaluation pipelines.
- **Product & Program Managers:** Translate this concept into user impact and rollout plans.
- **Communications & Enablement:** Align messaging, FAQs, and enablement materials using this definition.

## Practice & apply
- Add this concept to onboarding materials so teammates share a common baseline.
- Link supporting research or documentation in your internal wiki for deeper study.
- Prototype behaviour changes in a sandbox notebook and capture prompt or decoding settings for others.
- Share findings with enablement so downstream teams understand model implications.
- Share takeaways with the accountable roles listed above so actions land with the right owners.

## Short definition
Generative model that iteratively denoises random noise to synthesize images, audio, or other data.

## Long definition
Diffusion models generate content by reversing a noising process. During training, clean data samples are progressively corrupted with Gaussian noise. The model learns to predict the noise at each step, effectively mapping from noisy inputs back to structure. During inference, the reverse process starts with pure noise and iteratively denoises toward a coherent sample over dozens or hundreds of timesteps. Diffusion models deliver state-of-the-art image and audio synthesis quality, control, and diversity compared with GANs or VAEs, but they can be computationally intensive. Product teams use guidance techniques, safety filters, and prompt engineering to align outputs with brand expectations. Engineers manage sampler choice, scheduler parameters, and hardware acceleration to meet latency targets. Governance stakeholders evaluate diffusion workflows for intellectual property, misinformation, and safety risks, since the models can produce realistic but fabricated content.

## Audience perspectives
- **Exec:** Diffusion models create images or audio by gradually refining random noise into something recognizable.
- **Engineer:** Train with forward noising and reverse denoising steps; deploy with schedulers (DDIM, Euler) and classifier-free guidance to control quality and speed.

## Examples
**Do**
- Log prompt, seed, and sampler metadata to reproduce outputs for audits.
- Apply content moderation and watermarking to manage safety and attribution.

**Don't**
- Assume diffusion outputs are free from copyright or bias concerns.
- Ignore the compute cost of small timestep adjustments on production workloads.

## Governance
- **NIST RMF tags:** risk_management, transparency
- **Risk notes:** Hyper-realistic outputs raise IP, misinformation, and safety challenges that must be documented and mitigated.

## Relationships
- **Broader:** generative ai
- **Related:** synthetic data, guardrails, safety evaluation

!!! info "Something missing?"
    Suggest examples or clarifications via the [term request intake](../term-request.md) and mention 'diffusion model'.

## Citations
- [Wikipedia AI Glossary](https://en.wikipedia.org/wiki/Glossary_of_artificial_intelligence)
- [Google ML Glossary](https://developers.google.com/machine-learning/glossary)
- [Hugging Face Glossary](https://huggingface.co/docs/transformers/en/glossary)

_License: CC BY-SA 4.0_

_Source file: `data/terms/diffusion-model.yml`_
