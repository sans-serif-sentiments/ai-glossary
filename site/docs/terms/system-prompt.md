<!--
  This file is auto-generated by scripts/render_docs.py. Do not edit manually.
-->

# system prompt

**Aliases:** system instruction, base prompt
**Categories:** LLM Core
**Roles:** Data Science & Research, Engineering & Platform, Product & Program Managers
**Part of speech:** `noun_phrase`
**Status:** <span class="status-chip status-approved">Approved</span> (Last reviewed: 2025-10-10)

!!! tip "Put it into practice"
    Review the [Prompt Engineering Playbook](../prompting.md) before shipping updates.

## Role takeaways
- **Data Science & Research:** Incorporate the metric or method into evaluation pipelines.
- **Engineering & Platform:** Document implementation requirements and operational caveats.
- **Product & Program Managers:** Translate this concept into user impact and rollout plans.

## Practice & apply
- Prototype behaviour changes in a sandbox notebook and capture prompt or decoding settings for others.
- Share findings with enablement so downstream teams understand model implications.
- Share takeaways with the accountable roles listed above so actions land with the right owners.

## Short definition
Foundational instruction that sets role, tone, and guardrails for an AI assistant before user input.

## Long definition
A system prompt is the preamble sent to a conversational model before user messages to establish behavior, policies, and capabilities. It can describe persona, writing style, safety instructions, tool usage rules, or escalation paths. Because the system prompt is prepended to every conversation turn, it shapes how the model interprets later inputs and resolves conflicts between user requests and organizational policy. Product teams iterate on system prompts to balance friendliness with compliance, while engineers version and test them like code, running regression suites to detect unexpectedly permissive outputs. Governance reviewers treat system prompts as formal policy artifacts: they require approval, change tracking, and alignment with risk controls such as prohibited content lists. Poorly maintained system prompts can drift, accumulate contradictory clauses, or leak internal policies if exposed, so teams pair them with automated linting and secret scanning.

## Audience perspectives
- **Exec:** Think of the system prompt as the playbook that keeps the assistant on-brand and on-policy before it ever talks to a user.
- **Engineer:** Immutable prefix in the prompt stack that defines instructions and tool contracts; version-controlled for audits and evals.

## Examples
**Do**
- Store system prompts in source control and run evaluations whenever they change.

**Don't**
- Embed sensitive credentials or private policies in the system prompt without access controls.

## Governance
- **NIST RMF tags:** transparency, accountability
- **Risk notes:** Unreviewed system prompts can encode unsafe behaviors or leak confidential policy guidance.

## Relationships
- **Broader:** prompt engineering
- **Narrower:** safety prompt
- **Related:** guardrails, temperature, tool use

!!! info "Something missing?"
    Suggest examples or clarifications via the [term request intake](../term-request.md) and mention 'system prompt'.

## Citations
- [Anthropic – System Prompts](https://docs.anthropic.com/en/docs/build-with-claude/system-prompts)
- [Microsoft – System Message Guidance](https://learn.microsoft.com/en-us/azure/ai-foundry/openai/concepts/system-message)
- [Stanford HAI Brief Definitions](https://hai.stanford.edu/news/brief-definitions)

_License: CC BY-SA 4.0_

_Source file: `data/terms/system-prompt.yml`_
