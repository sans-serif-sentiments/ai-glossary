<!--
  This file is auto-generated by scripts/render_docs.py. Do not edit manually.
-->

# log probability

**Aliases:** logprob, token log probability
**Categories:** LLM Core
**Roles:** Data Science & Research, Engineering & Platform, Product & Program Managers
**Part of speech:** `noun_phrase`
**Status:** <span class="status-chip status-approved">Approved</span> (Last reviewed: 2025-10-09)

## Role takeaways
- **Data Science & Research:** Incorporate the metric or method into evaluation pipelines.
- **Engineering & Platform:** Document implementation requirements and operational caveats.
- **Product & Program Managers:** Translate this concept into user impact and rollout plans.

## Practice & apply
- Prototype behaviour changes in a sandbox notebook and capture prompt or decoding settings for others.
- Share findings with enablement so downstream teams understand model implications.
- Share takeaways with the accountable roles listed above so actions land with the right owners.

## Short definition
Logarithm of a token’s probability, used to inspect model confidence and guide decoding tweaks.

## Long definition
Log probability represents the natural logarithm of a token’s predicted probability during generation. Because probabilities multiply across sequence lengths, working in log space avoids numerical underflow and makes it easier to compare relative likelihoods. Tooling that surfaces token-level logprobs helps practitioners debug why a model chose specific words, identify low-confidence spans for post-processing, and implement rejection sampling. Product teams use logprob thresholds to trigger fallbacks, escalate to humans, or annotate responses with confidence indicators. Engineers rely on logprobs to enforce constraints such as toxicity caps, apply repetition penalties, or calibrate beam search scores. Governance stakeholders treat logprob telemetry as part of audit trails, correlating low-confidence regions with incidents or hallucinations. Capturing and analyzing log probabilities thus supports transparency requirements and informs mitigation strategies when behavior drifts over time.

## Audience perspectives
- **Exec:** Log probabilities surface how confident the model was about each word, which can trigger reviews when confidence drops.
- **Engineer:** Natural-log scores from the softmax output that accumulate across tokens; useful for diagnostics, penalties, and rejection sampling.

## Examples
**Do**
- Flag completions where average logprob falls below a threshold and route them for human review.

**Don't**
- Expose raw logprob values to end users without context or calibration.

## Governance
- **NIST RMF tags:** transparency, validity
- **Risk notes:** Missing logprob telemetry makes it harder to audit why unsafe or incorrect outputs were produced.

## Relationships
- **Broader:** decoding
- **Related:** temperature, top-k sampling, evaluation

!!! info "Something missing?"
    Suggest examples or clarifications via the [term request intake](../term-request.md) and mention 'log probability'.

## Citations
- [Google ML Glossary](https://developers.google.com/machine-learning/glossary)
- [Hugging Face Glossary](https://huggingface.co/docs/transformers/en/glossary)
- [NIST AI RMF Glossary](https://www.nist.gov/itl/ai-risk-management-framework)

_License: CC BY-SA 4.0_

_Source file: `data/terms/log-probability.yml`_
