<!--
  This file is auto-generated by scripts/render_docs.py. Do not edit manually.
-->

# temperature

**Aliases:** sampling temperature, softmax temperature
**Categories:** LLM Core
**Roles:** Data Science & Research, Engineering & Platform, Product & Program Managers
**Part of speech:** `noun`
**Status:** <span class="status-chip status-approved">Approved</span> (Last reviewed: 2025-10-10)

!!! tip "Put it into practice"
    Experiment with settings using the [Prompt Engineering Playbook](../prompting.md).

## Role takeaways
- **Data Science & Research:** Incorporate the metric or method into evaluation pipelines.
- **Engineering & Platform:** Document implementation requirements and operational caveats.
- **Product & Program Managers:** Translate this concept into user impact and rollout plans.

## Practice & apply
- Prototype behaviour changes in a sandbox notebook and capture prompt or decoding settings for others.
- Share findings with enablement so downstream teams understand model implications.
- Share takeaways with the accountable roles listed above so actions land with the right owners.

## Short definition
Decoding parameter that controls how random or deterministic a model’s outputs are.

## Long definition
Temperature adjusts the softness of the probability distribution used when sampling tokens during decoding. A low temperature sharpens the distribution so the model consistently chooses the highest-probability token, producing deterministic, conservative responses. Higher temperatures flatten the distribution, increasing the likelihood of picking lower-probability tokens that introduce creativity but also raise the risk of incoherence or policy violations. Product teams tune temperature per use case—customer support bots typically prefer lower settings, while brainstorming assistants tolerate higher ones. Engineers may pair temperature with top-k or nucleus sampling to constrain randomness while preserving diversity. Governance reviewers monitor temperature configurations because overly permissive settings can bypass guardrails validated at default values, leading to unpredictable behavior in production. Documenting temperature choices and evaluating them against safety scenarios is therefore part of responsible deployment.

## Audience perspectives
- **Exec:** Temperature is the creativity dial—turn it down for consistency, up for variety.
- **Engineer:** Softmax scaling factor applied prior to sampling; inversely proportional to distribution sharpness and deterministic behavior.

## Examples
**Do**
- Run evaluation suites at multiple temperature settings to quantify factual accuracy trade-offs.

**Don't**
- Ship higher temperatures to production without revisiting safety and compliance test results.

## Governance
- **NIST RMF tags:** robustness, transparency
- **Risk notes:** High temperatures can invalidate prior safety assessments and increase hallucination incidents.

## Relationships
- **Broader:** decoding
- **Narrower:** temperature annealing
- **Related:** top-k sampling, top-p sampling, hallucination

!!! info "Something missing?"
    Suggest examples or clarifications via the [term request intake](../term-request.md) and mention 'temperature'.

## Citations
- [Google ML Glossary](https://developers.google.com/machine-learning/glossary)
- [Hugging Face Glossary](https://huggingface.co/docs/transformers/en/glossary)
- [Wikipedia AI Glossary](https://en.wikipedia.org/wiki/Glossary_of_artificial_intelligence)

_License: CC BY-SA 4.0_

_Source file: `data/terms/temperature.yml`_
