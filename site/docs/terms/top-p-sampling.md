<!--
  This file is auto-generated by scripts/render_docs.py. Do not edit manually.
-->

# top-p sampling

**Aliases:** nucleus sampling, p-sampling
**Categories:** LLM Core
**Roles:** Data Science & Research, Engineering & Platform, Product & Program Managers
**Part of speech:** `process`
**Status:** <span class="status-chip status-approved">Approved</span> (Last reviewed: 2025-10-09)

!!! tip "Put it into practice"
    See the [Prompt Engineering Playbook](../prompting.md) for tuning tips.

## Role takeaways
- **Data Science & Research:** Incorporate the metric or method into evaluation pipelines.
- **Engineering & Platform:** Document implementation requirements and operational caveats.
- **Product & Program Managers:** Translate this concept into user impact and rollout plans.

## Practice & apply
- Prototype behaviour changes in a sandbox notebook and capture prompt or decoding settings for others.
- Share findings with enablement so downstream teams understand model implications.
- Share takeaways with the accountable roles listed above so actions land with the right owners.

## Short definition
Decoding strategy that samples from the smallest set of tokens whose probabilities sum to p.

## Long definition
Top-p sampling, also called nucleus sampling, builds a dynamic shortlist of candidate tokens whose cumulative probability exceeds a threshold p. Instead of fixing the number of options, the method adapts to the shape of the probability distribution: sharply peaked distributions produce small candidate sets, while flatter distributions expand the pool. This flexibility makes top-p useful for preserving coherence in confident contexts while still allowing creative variations when the model is less certain. Engineers tune the p value in tandem with temperature to achieve the desired balance between determinism and variety. Product teams rely on the technique for experiences like storytelling, marketing copy, or brainstorming where monotone responses are undesirable. Governance teams record chosen p values alongside evaluation evidence, recognizing that higher thresholds can surface content not vetted during safety reviews. Monitoring how p interacts with policy classifiers and guardrails is an integral part of ongoing risk management.

## Audience perspectives
- **Exec:** A probability threshold that keeps responses varied without wandering too far off message.
- **Engineer:** Accumulate token probabilities until they exceed p, normalize, then sampleâ€”yielding adaptive candidate sets per step.

## Examples
**Do**
- Test critical workflows at p values of 0.7, 0.9, and 0.95 to document behavioral differences.

**Don't**
- Use high p thresholds for regulated communications without updated compliance sign-off.

## Governance
- **NIST RMF tags:** robustness, transparency
- **Risk notes:** Large nucleus thresholds can introduce unvetted behaviors and may invalidate safety testing baselines.

## Relationships
- **Broader:** decoding
- **Related:** temperature, top-k sampling, greedy decoding

!!! info "Something missing?"
    Suggest examples or clarifications via the [term request intake](../term-request.md) and mention 'top-p sampling'.

## Citations
- [Hugging Face Glossary](https://huggingface.co/docs/transformers/en/glossary)
- [Google ML Glossary](https://developers.google.com/machine-learning/glossary)
- [Stanford HAI Brief Definitions](https://hai.stanford.edu/news/brief-definitions)

_License: CC BY-SA 4.0_

_Source file: `data/terms/top-p-sampling.yml`_
