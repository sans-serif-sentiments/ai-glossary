<!--
  This file is auto-generated by scripts/render_docs.py. Do not edit manually.
-->

# activation function

**Aliases:** nonlinearity
**Categories:** Foundations
**Roles:** Data Science & Research, Engineering & Platform, Product & Program Managers
**Part of speech:** `concept`
**Status:** <span class="status-chip status-approved">Approved</span> (Last reviewed: 2025-10-10)

## Role takeaways
- **Data Science & Research:** Incorporate the metric or method into evaluation pipelines.
- **Engineering & Platform:** Document implementation requirements and operational caveats.
- **Product & Program Managers:** Translate this concept into user impact and rollout plans.

## Practice & apply
- Add this concept to onboarding materials so teammates share a common baseline.
- Link supporting research or documentation in your internal wiki for deeper study.
- Share takeaways with the accountable roles listed above so actions land with the right owners.

## Short definition
Mathematical transformation applied to a neuron’s weighted sum that lets neural networks model nonlinear relationships and control signal range.

## Long definition
Activation functions are the nonlinear transformations applied to each neuron’s weighted sum before it flows to the next layer. By shaping the signal—through functions like ReLU, GELU, or sigmoid—they let neural networks approximate nonlinear decision boundaries, regulate gradient flow, and cap output ranges for probabilistic tasks. Engineers select activations that keep gradients stable during backpropagation, minimise vanishing or exploding values, and align with hardware constraints. Data scientists evaluate choices empirically because the same architecture can converge faster or generalise better when paired with an activation that matches the distribution of features. Product teams experience the impact in training throughput, latency, and quality metrics that show up in customer-facing capabilities. Governance and safety partners care because misconfigured activations can cause brittle behaviour, numerical overflow, or fairness regressions that invalidate evaluation baselines. Maintaining a documented activation strategy, paired with tests that watch for saturation or drift when models are retrained, keeps optimisation explainable and reproducible.

## Audience perspectives
- **Exec:** Signals whether the model can keep improving accuracy without destabilising costs or violating quality guardrails.
- **Engineer:** Choose activations that maintain gradient health, are supported by deployment hardware, and have regression tests for saturation.

## Examples
**Do**
- Run ablation tests comparing ReLU, GELU, and SiLU to confirm which activation delivers the best loss convergence on production data.

**Don't**
- Ship a new activation into production without checking for output range shifts that could break downstream calibration.

## Governance
- **NIST RMF tags:** validity, reliability
- **Risk notes:** Unvetted activations can destabilise training, overflow numeric ranges, or skew evaluation metrics, undermining claims about model quality.

## Relationships
- **Broader:** model architecture
- **Related:** gradient descent, loss function, regularization

!!! info "Something missing?"
    Suggest examples or clarifications via the [term request intake](../term-request.md) and mention 'activation function'.

## Citations
- [CS231n – Activation Functions](https://cs231n.github.io/neural-networks-1/#actfun)
- [PyTorch Documentation – Non-linear Activations](https://docs.pytorch.org/docs/stable/nn.html)

_License: CC BY-SA 4.0_

_Source file: `data/terms/activation-function.yml`_
