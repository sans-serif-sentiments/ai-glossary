<!--
  This file is auto-generated by scripts/render_docs.py. Do not edit manually.
-->

# privacy

**Aliases:** data privacy, information privacy
**Categories:** Governance & Risk
**Roles:** Communications & Enablement, Legal & Compliance, Policy & Risk, Product & Program Managers
**Part of speech:** `concept`
**Status:** <span class="status-chip status-approved">Approved</span> (Last reviewed: 2025-09-29)

## Role takeaways
- **Communications & Enablement:** Align messaging, FAQs, and enablement materials using this definition.
- **Legal & Compliance:** Assess contractual and regulatory obligations tied to this term.
- **Policy & Risk:** Map the definition to governance controls and review checklists.
- **Product & Program Managers:** Translate this concept into user impact and rollout plans.

## Practice & apply
- Map this term to the governance dashboard and record accountable owners in the backlog.
- Review current regulatory guidance or internal policy notes linked from the resources page before sign-off.
- Share takeaways with the accountable roles listed above so actions land with the right owners.

## Short definition
Principle of limiting data collection, use, and exposure to protect individuals’ information.

## Long definition
Privacy in AI systems focuses on controlling how personal or sensitive data is collected, processed, and retained. Regulations such as GDPR, CCPA, and sector-specific laws establish legal obligations for transparency, consent, minimization, and user rights. In machine learning, privacy risks arise from training data, prompts, logs, and model outputs that may reveal personal information. Teams mitigate these risks through data minimization, access controls, anonymization, synthetic data, and privacy-enhancing technologies like differential privacy. Product leaders coordinate privacy reviews with legal counsel when launching new features, while engineers implement safeguards in data pipelines, storage, and logging. Governance programs track privacy impact assessments, retention schedules, and incident response plans. Maintaining rigorous privacy practices preserves user trust and avoids regulatory penalties, making it a foundational requirement for responsible AI deployments.

## Audience perspectives
- **Exec:** Privacy keeps user data protected and ensures AI initiatives comply with laws and customer expectations.
- **Engineer:** Limit collection, apply technical controls, and document handling of personal data across training and inference workflows.

## Examples
**Do**
- Run privacy impact assessments before ingesting new data sources for fine-tuning.

**Don't**
- Log raw prompts that contain personal identifiers without redaction or retention limits.

## Governance
- **NIST RMF tags:** privacy, risk_management
- **Risk notes:** Weak privacy controls can expose personal data, triggering legal liability and loss of trust.

## Relationships
- **Broader:** responsible ai
- **Related:** guardrails, model governance, incident response

!!! info "Something missing?"
    Suggest examples or clarifications via the [term request intake](../term-request.md) and mention 'privacy'.

## Citations
- [NIST AI RMF Glossary](https://www.nist.gov/itl/ai-risk-management-framework)
- [OECD – Privacy Guidelines](https://ico.org.uk/for-organisations/uk-gdpr-guidance-and-resources/)
- [Wikipedia AI Glossary](https://en.wikipedia.org/wiki/Glossary_of_artificial_intelligence)

_License: CC BY-SA 4.0_

_Source file: `data/terms/privacy.yml`_
