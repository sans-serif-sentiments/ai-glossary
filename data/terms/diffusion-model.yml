term: diffusion model
aliases:
- denoising diffusion model
- score-based model
categories:
- Foundations
- LLM Core
roles:
- engineering
- data_science
- product
- communications
part_of_speech: noun
short_def: Generative model that iteratively denoises random noise to synthesize images,
  audio, or other data.
long_def: Diffusion models generate content by reversing a noising process. During
  training, clean data samples are progressively corrupted with Gaussian noise. The
  model learns to predict the noise at each step, effectively mapping from noisy inputs
  back to structure. During inference, the reverse process starts with pure noise
  and iteratively denoises toward a coherent sample over dozens or hundreds of timesteps.
  Diffusion models deliver state-of-the-art image and audio synthesis quality, control,
  and diversity compared with GANs or VAEs, but they can be computationally intensive.
  Product teams use guidance techniques, safety filters, and prompt engineering to
  align outputs with brand expectations. Engineers manage sampler choice, scheduler
  parameters, and hardware acceleration to meet latency targets. Governance stakeholders
  evaluate diffusion workflows for intellectual property, misinformation, and safety
  risks, since the models can produce realistic but fabricated content.
audiences:
  exec: Diffusion models create images or audio by gradually refining random noise
    into something recognizable.
  engineer: Train with forward noising and reverse denoising steps; deploy with schedulers
    (DDIM, Euler) and classifier-free guidance to control quality and speed.
examples:
  do:
  - Log prompt, seed, and sampler metadata to reproduce outputs for audits.
  - Apply content moderation and watermarking to manage safety and attribution.
  dont:
  - Assume diffusion outputs are free from copyright or bias concerns.
  - Ignore the compute cost of small timestep adjustments on production workloads.
governance:
  nist_rmf_tags:
  - risk_management
  - transparency
  risk_notes: Hyper-realistic outputs raise IP, misinformation, and safety challenges
    that must be documented and mitigated.
relationships:
  broader:
  - generative ai
  related:
  - synthetic data
  - guardrails
  - safety evaluation
citations:
- source: Wikipedia AI Glossary
  url: https://en.wikipedia.org/wiki/Glossary_of_artificial_intelligence
- source: Google ML Glossary
  url: https://developers.google.com/machine-learning/glossary
- source: Hugging Face Glossary
  url: https://huggingface.co/docs/transformers/en/glossary
license: CC BY-SA 4.0
status: approved
last_reviewed: '2025-10-09'
