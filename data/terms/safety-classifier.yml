term: safety classifier
aliases:
- safety filter
- policy classifier
categories:
- Governance & Risk
roles:
- security
- policy
- product
- engineering
part_of_speech: noun_phrase
short_def: Model that detects policy-violating or risky content before or after generation.
long_def: A safety classifier screens prompts and outputs to catch disallowed topics
  such as self-harm, extremism, or personal data. Classifiers can run pre-generation
  (blocking unsafe inputs), post-generation (filtering responses), or both. They complement
  prompt-based guardrails, providing a measurable signal that policies are enforced.
  Security and policy teams curate labeled datasets, engineering integrates the classifier
  into pipelines, and product owners tune messaging when content is blocked. Mature
  teams monitor precision/recall, recalibrate thresholds, and pair classifiers with
  human review for high-severity categories. Classifiers require ongoing evaluation
  to avoid overblocking legitimate use or missing novel abuse patterns.
audiences:
  exec: Treat safety classifiers as a control with metrics, owners, and effectiveness
    reviews.
  engineer: Log classifier scores, decisions, and overrides for auditing and incident
    analysis.
examples:
  do:
  - Version classifier thresholds and align them with published policy requirements.
  - Run adversarial tests to catch bypasses introduced by new jailbreaks.
  dont:
  - Rely solely on classifiers without human review for high-risk categories.
  - Deploy classifiers trained on outdated policy definitions.
governance:
  nist_rmf_tags:
  - monitoring
  - risk_management
  - security
  risk_notes: Poorly tuned classifiers erode trust—either by letting harmful content
    through or by overblocking.
relationships:
  broader:
  - guardrails
  related:
  - jailbreak prompt
  - prompt injection
  - robust prompting
citations:
- source: OpenAI – Moderation Tools
  url: https://learn.microsoft.com/en-us/azure/ai-foundry/responsible-ai/openai/overview
- source: Google Cloud – Content Safety Tools
  url: https://cloud.google.com/blog/products/ai-machine-learning/responsible-ai-toolkits-content-safety
license: CC BY-SA 4.0
status: approved
last_reviewed: '2025-10-09'
